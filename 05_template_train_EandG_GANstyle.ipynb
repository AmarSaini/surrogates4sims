{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:32:25.017356Z",
     "start_time": "2020-03-17T21:32:23.674291Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/widemann1/anaconda3/envs/amar/lib/python3.7/site-packages/tqdm/autonotebook.py:17: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "# EXPORT\n",
    "# --- Must haves ---\n",
    "import os, sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "\n",
    "from surrogates4sims.datasets import MantaFlowDataset, getSingleSim, createMantaFlowTrainTest\n",
    "\n",
    "from surrogates4sims.utils import create_opt, create_one_cycle, find_lr, printNumModelParams, \\\n",
    "                                    rmse, writeMessage, plotSampleWprediction, plotSampleWpredictionByChannel, \\\n",
    "                                    plotSample, curl, jacobian, stream2uv\n",
    "\n",
    "from surrogates4sims.models import Generator, Encoder, AE, AE_no_P\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:32:25.028506Z",
     "start_time": "2020-03-17T21:32:25.019946Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gangam_style_training_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_epochs100'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model name, for tensorboard recording and checkpointing purposes.\n",
    "versionName = \"gangam_style_training\"\n",
    "\n",
    "# GPU Numbers to use. Comma seprate them for multi-GPUs.\n",
    "\n",
    "gpu_ids = \"2\"\n",
    "# path to load model weights.\n",
    "pretrained_path = None\n",
    "\n",
    "# rate at which to record metrics. (number of batches to average over when recording metrics, e.g. \"every 5 batches\")\n",
    "tensorboard_rate = 5\n",
    "\n",
    "# number of epochs to train. This is defined here so we can use the OneCycle LR Scheduler.\n",
    "epochs = 100\n",
    "\n",
    "# Data Directory\n",
    "dataDirec = '/data/mantaFlowSim/data/smoke_pos21_size5_f200/v'\n",
    "reverseXY = False \n",
    "\n",
    "# checkpoint directory\n",
    "cps = 'cps'\n",
    "tensorboard_direc = \"tb\"\n",
    "\n",
    "findLRs = False # only do this if you're trying to set the LR of E, G. It blows up the GPU \n",
    "\n",
    "# hyper-params\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "testSplit = .1\n",
    "bz = 8\n",
    "numSamplesToKeep = np.infty #if not debugging\n",
    "latentDim = 16\n",
    "filters = 16\n",
    "num_conv = 4\n",
    "simLen = 200\n",
    "stack = True\n",
    "simVizIndex = 0 # sim in the test set to visualize\n",
    "createStreamFcn = False\n",
    "doJacobian = True\n",
    "versionName = versionName + '_latentDim{}_filters{}_bz{}_numConv{}_stream{}_jacobian{}_epochs{}'.format(latentDim,filters,bz,num_conv,createStreamFcn,doJacobian,epochs)\n",
    "versionName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Personal GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:32:25.208616Z",
     "start_time": "2020-03-17T21:32:25.030513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 17 21:32:25 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 430.40       Driver Version: 430.40       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN Xp            On   | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 23%   21C    P8     8W / 250W |   1042MiB / 12196MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  TITAN Xp            On   | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 23%   21C    P8     8W / 250W |      1MiB / 12196MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  TITAN Xp            On   | 00000000:81:00.0 Off |                  N/A |\r\n",
      "| 41%   65C    P2   139W / 250W |   1042MiB / 12196MiB |     36%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  TITAN Xp            On   | 00000000:82:00.0 Off |                  N/A |\r\n",
      "| 23%   23C    P8     9W / 250W |      1MiB / 12196MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     11794      C   ...idemann1/anaconda3/envs/amar/bin/python  1031MiB |\r\n",
      "|    2     15222      C   ...idemann1/anaconda3/envs/amar/bin/python  1031MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:32:25.216155Z",
     "start_time": "2020-03-17T21:32:25.211872Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:32:25.243834Z",
     "start_time": "2020-03-17T21:32:25.218475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:32:25.254687Z",
     "start_time": "2020-03-17T21:32:25.246310Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "if device.type == 'cuda':\n",
    "    print(cuda.is_available())\n",
    "    print(cuda.device_count())\n",
    "    print(cuda.current_device())\n",
    "    print(cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:32:28.573015Z",
     "start_time": "2020-03-17T21:32:25.259405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 17 21:32:28 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 430.40       Driver Version: 430.40       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN Xp            On   | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 23%   21C    P8     8W / 250W |   1042MiB / 12196MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  TITAN Xp            On   | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 23%   21C    P8     8W / 250W |      1MiB / 12196MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  TITAN Xp            On   | 00000000:81:00.0 Off |                  N/A |\r\n",
      "| 42%   65C    P2   124W / 250W |   1571MiB / 12196MiB |     48%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  TITAN Xp            On   | 00000000:82:00.0 Off |                  N/A |\r\n",
      "| 23%   24C    P8     9W / 250W |      1MiB / 12196MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     11794      C   ...idemann1/anaconda3/envs/amar/bin/python  1031MiB |\r\n",
      "|    2     15222      C   ...idemann1/anaconda3/envs/amar/bin/python  1031MiB |\r\n",
      "|    2     25866      C   ...idemann1/anaconda3/envs/amar/bin/python   529MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(5, device=device.type)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets & Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:32:28.663177Z",
     "start_time": "2020-03-17T21:32:28.577910Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 2000)\n"
     ]
    }
   ],
   "source": [
    "trainData, testData = createMantaFlowTrainTest(dataDirec,simLen,testSplit,seed)\n",
    "print((len(trainData),len(testData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.210337Z",
     "start_time": "2020-03-17T21:32:28.664470Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:03<00:00, 568.82it/s]\n",
      "100%|██████████| 19000/19000 [00:35<00:00, 542.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19000, 2000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets may be smaller because: numSamplesToKeep \n",
    "testDataset = MantaFlowDataset(testData, reverseXY=reverseXY, numToKeep=numSamplesToKeep, AE=False)\n",
    "trainDataset = MantaFlowDataset(trainData, reverseXY=reverseXY,numToKeep=numSamplesToKeep, AE=False)\n",
    "len(trainDataset), len(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.216507Z",
     "start_time": "2020-03-17T21:33:07.212781Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "trainDataLoader = DataLoader(dataset=trainDataset, batch_size=bz, shuffle=True, drop_last=True)\n",
    "testDataLoader = DataLoader(dataset=testDataset, batch_size=bz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the models need to take data to be built. It's kinda weird. I may look into fix this later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.245555Z",
     "start_time": "2020-03-17T21:33:07.218093Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 2, 128, 96]), torch.Size([8, 3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,p = next(iter(testDataLoader))\n",
    "X = X.to(device)\n",
    "p = p.to(device)\n",
    "X.shape, p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.268867Z",
     "start_time": "2020-03-17T21:33:07.247648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (act): LeakyReLU(negative_slope=0.01)\n",
       "  (conv1): Conv2d(2, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convs): Sequential(\n",
       "    (0): convBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (downSampleLayer): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): convBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (downSampleLayer): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (2): convBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(48, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (downSampleLayer): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (3): convBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (downSampleLayer): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (4): convBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(80, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (downSampleLayer): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=1152, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = Encoder(X,filters,latentDim,num_conv=num_conv).to(device)\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.273817Z",
     "start_time": "2020-03-17T21:33:07.270058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 layers require gradients (unfrozen) out of 54 layers\n",
      "99,792 parameters require gradients (unfrozen) out of 99,792 parameters\n"
     ]
    }
   ],
   "source": [
    "printNumModelParams(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.543892Z",
     "start_time": "2020-03-17T21:33:07.275125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = E(X)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.548679Z",
     "start_time": "2020-03-17T21:33:07.545113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2, 128,  96])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape = torch.tensor(X[0].shape)\n",
    "output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.560098Z",
     "start_time": "2020-03-17T21:33:07.550101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (linear): Linear(in_features=16, out_features=768, bias=True)\n",
       "  (convTransBlockLayers): Sequential(\n",
       "    (0): convTransBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (1): convTransBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (2): convTransBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(48, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (3): convTransBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "        (2): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): LeakyReLU(negative_slope=0.01)\n",
       "        (4): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (7): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lastConv): Conv2d(80, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = Generator(z, filters, output_shape,\n",
    "                 num_conv=num_conv, conv_k=3, last_k=3, repeat=0, \n",
    "                 skip_connection=False, act=nn.LeakyReLU(), stack=stack)\n",
    "G = G.to(device)\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.564488Z",
     "start_time": "2020-03-17T21:33:07.561194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 layers require gradients (unfrozen) out of 36 layers\n",
      "65,442 parameters require gradients (unfrozen) out of 65,442 parameters\n"
     ]
    }
   ],
   "source": [
    "printNumModelParams(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.574651Z",
     "start_time": "2020-03-17T21:33:07.565828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 128, 96])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xhat = G(z)\n",
    "Xhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.581777Z",
     "start_time": "2020-03-17T21:33:07.575893Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def L1_loss(pred, target):\n",
    "    return torch.mean(torch.abs(pred - target))\n",
    "\n",
    "\n",
    "def jacobian_loss(pred, target, device='cpu'):\n",
    "    return L1_loss(jacobian(pred, device), jacobian(target, device))\n",
    "\n",
    "\n",
    "def curl_loss(pred, target, device):\n",
    "    return L1_loss(curl(pred, device), curl(target, device))\n",
    "\n",
    "\n",
    "L = nn.MSELoss()\n",
    "\n",
    "\n",
    "def p_loss(pred, target):\n",
    "    return L(pred[:, -target.shape[1]:], target)\n",
    "\n",
    "\n",
    "def loss(pred, target, device):\n",
    "    Lj = 0\n",
    "    if createStreamFcn:\n",
    "        L1 = L1_loss(stream2uv(pred, device), target)\n",
    "    else:\n",
    "        L1 = L1_loss(pred, target)\n",
    "    if doJacobian:\n",
    "        Lj = jacobian_loss(pred, target, device)\n",
    "    return L1 + Lj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.604382Z",
     "start_time": "2020-03-17T21:33:07.583124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0., device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0481, device='cuda:0', grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(Xhat,Xhat,device), loss(Xhat,X,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.609929Z",
     "start_time": "2020-03-17T21:33:07.605660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4323, device='cuda:0', grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_loss(z,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer and LR Scheduler for Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little bit tricky. We have to modify the Datasets so the lr_finder works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.615315Z",
     "start_time": "2020-03-17T21:33:07.612900Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "if findLRs:\n",
    "    opt_E = create_opt(1e-7,E)\n",
    "    find_lr(E,opt_E,p_loss,device,trainDataLoader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.620678Z",
     "start_time": "2020-03-17T21:33:07.617167Z"
    }
   },
   "outputs": [],
   "source": [
    "max_lr_E = .00001\n",
    "start_lr_E = max_lr_E/10\n",
    "opt_E = create_opt(max_lr_E,E)\n",
    "#opt = torch.optim.Adam(model.parameters(),lr=start_lr,betas=(.5,.999))\n",
    "lr_scheduler_E = create_one_cycle(opt_E,max_lr_E,epochs,trainDataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T20:43:13.929345Z",
     "start_time": "2020-03-16T20:43:13.925474Z"
    }
   },
   "source": [
    "## Optimizer and LR Scheduler for Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.627227Z",
     "start_time": "2020-03-17T21:33:07.622317Z"
    }
   },
   "outputs": [],
   "source": [
    "if findLRs:\n",
    "    from copy import deepcopy\n",
    "    \n",
    "    ae_model = AE_no_P(E,G).to(device)\n",
    "\n",
    "    AE_dataset = deepcopy(trainDataset)\n",
    "    AE_dataset.AE = True\n",
    "\n",
    "    AE_dataLoader = DataLoader(AE_dataset,batch_size=bz,shuffle=True)\n",
    "\n",
    "    xx,yy = next(iter(AE_dataLoader))\n",
    "\n",
    "    def loss4LrFinder(pred,target):\n",
    "        return loss(pred,target,device)\n",
    "\n",
    "    # put it on the cpu so you can save gpu space for training later.\n",
    "    opt = create_opt(1e-7,ae_model)\n",
    "    find_lr(ae_model,opt,loss4LrFinder,device,AE_dataLoader) # this breaks because the output of trainDataLoader is (X,y), X\n",
    "    # LRFinder does not like the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.633027Z",
     "start_time": "2020-03-17T21:33:07.628752Z"
    }
   },
   "outputs": [],
   "source": [
    "max_lr_G = .00001\n",
    "start_lr_G = 5*max_lr_G/10\n",
    "opt_G = create_opt(max_lr_G,G)\n",
    "#opt = torch.optim.Adam(model.parameters(),lr=start_lr,betas=(.5,.999))\n",
    "lr_scheduler_G = create_one_cycle(opt_G,max_lr_G,epochs,trainDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.639140Z",
     "start_time": "2020-03-17T21:33:07.634516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2375"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.655442Z",
     "start_time": "2020-03-17T21:33:07.641744Z"
    }
   },
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "def trainEpoch(myDataLoader, tensorboard_writer, E, G, opt_E, opt_G, loss,\n",
    "               metric, lr_scheduler_E, lr_scheduler_G, tensorboard_rate, device,\n",
    "               tensorboard_recorder_step, total_steps):\n",
    "\n",
    "    d_steps = 10\n",
    "    num_batches = len(myDataLoader)\n",
    "    \n",
    "    for bg in range(num_batches//d_steps):\n",
    "        running_loss = 0.0\n",
    "        running_rmse = 0.0\n",
    "        for d_step in range(d_steps):\n",
    "            Z = []\n",
    "            XX = []\n",
    "            cnt = 0\n",
    "            for i, sampleBatch in enumerate(myDataLoader, start=1):\n",
    "                cnt += 1\n",
    "                if cnt >= d_steps:\n",
    "                    break\n",
    "                    \n",
    "                # not sure if this is necessary\n",
    "                E.zero_grad()\n",
    "\n",
    "                X,p = sampleBatch[0],sampleBatch[1]\n",
    "                X = X.to(device)\n",
    "                p = p.to(device)\n",
    "\n",
    "                opt_E.zero_grad()\n",
    "\n",
    "                z = E(X)\n",
    "\n",
    "                pLoss = p_loss(z,p)\n",
    "                pLoss.backward()\n",
    "                opt_E.step()\n",
    "                \n",
    "                Z.append(z.detach())\n",
    "                XX.append(X.detach())\n",
    "\n",
    "                total_steps += 1\n",
    "\n",
    "            for z,X in zip(Z,XX):\n",
    "                opt_G.zero_grad()\n",
    "\n",
    "                #G\n",
    "                X_hat = G(z)\n",
    "                L1 = loss(X_hat,X,device)\n",
    "                L1.backward()\n",
    "                opt_G.step()\n",
    "                \n",
    "                \n",
    "            # loss\n",
    "            batch_loss = pLoss.item() + L1.item()\n",
    "            running_loss += batch_loss\n",
    "            lr_scheduler_E.step()\n",
    "            lr_scheduler_G.step()\n",
    "            \n",
    "            # --- Metrics Recording ---\n",
    "\n",
    "            # metrics\n",
    "            r = metric(X_hat, X)\n",
    "            running_rmse += r\n",
    "\n",
    "            # record lr change\n",
    "            tensorboard_writer.add_scalar(tag=\"Encoder_LR\", scalar_value=opt_E.param_groups[0]['lr'], global_step=total_steps)\n",
    "            tensorboard_writer.add_scalar(tag=\"Generator_LR\", scalar_value=opt_G.param_groups[0]['lr'], global_step=total_steps)\n",
    "\n",
    "            tensorboard_recorder_step += 1\n",
    "            avg_running_loss = running_loss/d_steps\n",
    "            avg_running_rmse = running_rmse/d_steps\n",
    "            tensorboard_writer.add_scalar(tag=\"Loss\", scalar_value=avg_running_loss, global_step=tensorboard_recorder_step)\n",
    "            tensorboard_writer.add_scalar(tag=metric.__name__, scalar_value=avg_running_rmse, global_step=tensorboard_recorder_step)\n",
    "\n",
    "\n",
    "    return batch_loss, tensorboard_recorder_step, total_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.665035Z",
     "start_time": "2020-03-17T21:33:07.656974Z"
    }
   },
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "def validEpoch(myDataLoader, tensorboard_writer, E, G, p_loss, loss, metric,\n",
    "               device, tensorboard_recorder_step):\n",
    "    running_loss = 0.0\n",
    "    running_rmse = 0.0\n",
    "    for i, sampleBatch in enumerate(myDataLoader, start=1):\n",
    "\n",
    "        # --- Metrics Recording ---\n",
    "\n",
    "        # gpu\n",
    "        X,p = sampleBatch[0],sampleBatch[1]\n",
    "        X = X.to(device)\n",
    "        p = p.to(device)\n",
    "        \n",
    "        perc = len(X)/len(myDataLoader.dataset)\n",
    "\n",
    "        # forward, no gradient calculations\n",
    "        with torch.no_grad():\n",
    "            z = E(X)\n",
    "            X_hat = G(z)\n",
    "\n",
    "        # loss\n",
    "        pl = p_loss(z,p)\n",
    "        L1 = loss(X_hat,X,device)\n",
    "        \n",
    "        running_loss += perc*(pl.item() + L1.item())\n",
    "\n",
    "        # metrics\n",
    "        r = metric(X_hat, X)\n",
    "        running_rmse += perc*r\n",
    "\n",
    "    avg_running_loss = running_loss\n",
    "    avg_running_rmse = running_rmse\n",
    "    tensorboard_writer.add_scalar(tag=\"Loss\", scalar_value=avg_running_loss, global_step=tensorboard_recorder_step)\n",
    "    tensorboard_writer.add_scalar(tag=metric.__name__, scalar_value=avg_running_rmse, global_step=tensorboard_recorder_step)\n",
    "\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.671235Z",
     "start_time": "2020-03-17T21:33:07.666251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints directory already exists :)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(cps)\n",
    "except:\n",
    "    print(\"checkpoints directory already exists :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-17T21:33:07.686701Z",
     "start_time": "2020-03-17T21:33:07.672594Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a summary writer.\n",
    "train_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'train'))\n",
    "test_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'valid'))\n",
    "tensorboard_recorder_step = 0\n",
    "total_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:04:05.805044Z",
     "start_time": "2020-03-17T21:33:07.688047Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Started Training ----------\n",
      "--- Epoch 1/100 ---\n",
      "trainLoss: 5.0611e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/100 [19:15<31:46:43, 1155.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better valLoss: 5.4109e-01, Saving models...\n",
      "--- Epoch 2/100 ---\n",
      "trainLoss: 4.0123e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [38:37<31:30:20, 1157.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better valLoss: 4.6458e-01, Saving models...\n",
      "--- Epoch 3/100 ---\n",
      "trainLoss: 2.0602e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/100 [56:23<30:26:56, 1130.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better valLoss: 2.4289e-01, Saving models...\n",
      "--- Epoch 4/100 ---\n",
      "trainLoss: 1.8882e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [1:13:58<29:32:04, 1107.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better valLoss: 2.0215e-01, Saving models...\n",
      "--- Epoch 5/100 ---\n",
      "trainLoss: 1.3942e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 5/100 [1:31:57<28:59:58, 1098.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better valLoss: 1.7819e-01, Saving models...\n",
      "--- Epoch 6/100 ---\n",
      "trainLoss: 2.0445e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [1:50:04<28:36:08, 1095.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better valLoss: 1.5044e-01, Saving models...\n",
      "--- Epoch 7/100 ---\n",
      "trainLoss: 1.1228e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [2:08:38<28:26:41, 1101.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better valLoss: 1.5042e-01, Saving models...\n",
      "--- Epoch 8/100 ---\n",
      "trainLoss: 9.7600e-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 8/100 [2:26:40<27:59:32, 1095.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 9/100 ---\n",
      "trainLoss: 6.7302e+03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [2:44:34<27:31:35, 1088.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 10/100 ---\n",
      "trainLoss: 3.0755e+06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [3:02:59<27:20:40, 1093.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 11/100 ---\n",
      "trainLoss: 3.5291e+13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 11/100 [3:20:41<26:48:05, 1084.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 12/100 ---\n",
      "trainLoss: 5.4205e+20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [3:38:45<26:29:49, 1083.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 13/100 ---\n",
      "trainLoss: 8.2457e+20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 13/100 [3:56:41<26:08:23, 1081.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 14/100 ---\n",
      "trainLoss: 1.5513e+21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [4:12:31<24:54:00, 1042.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 15/100 ---\n",
      "trainLoss: 1.2779e+21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [4:28:27<23:59:55, 1016.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 16/100 ---\n",
      "trainLoss: 6.7506e+21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 16/100 [4:44:21<23:16:48, 997.72s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 17/100 ---\n",
      "trainLoss: 6.0581e+21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [4:59:45<22:29:23, 975.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 18/100 ---\n",
      "trainLoss: 1.5595e+22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 18/100 [5:15:34<22:02:16, 967.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 19/100 ---\n",
      "trainLoss: 2.3404e+22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [5:30:53<21:26:39, 953.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 20/100 ---\n",
      "trainLoss: 1.2210e+22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [5:46:40<21:08:14, 951.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 21/100 ---\n",
      "trainLoss: 1.0341e+22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [6:02:18<20:47:18, 947.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 22/100 ---\n",
      "trainLoss: 1.2051e+22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 22/100 [6:17:44<20:22:53, 940.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 23/100 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-befdd3f5d679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                                                    \u001b[0mrmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler_E\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler_G\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                                    \u001b[0mtensorboard_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                                                                    tensorboard_recorder_step, total_steps)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mwriteMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainLoss: {:.4e}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mversionName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-546b5eca7243>\u001b[0m in \u001b[0;36mtrainEpoch\u001b[0;34m(myDataLoader, tensorboard_writer, E, G, opt_E, opt_G, loss, metric, lr_scheduler_E, lr_scheduler_G, tensorboard_rate, device, tensorboard_recorder_step, total_steps)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mX_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mL1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_hat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mL1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mopt_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amar/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/amar/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writeMessage('---------- Started Training ----------', versionName)\n",
    "bestLoss = np.infty\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):  # loop over the dataset multiple times\n",
    "    \n",
    "    writeMessage(\"--- Epoch {0}/{1} ---\".format(epoch, epochs), versionName)\n",
    "    \n",
    "    E.train()\n",
    "    G.train()\n",
    "    trainLoss, tensorboard_recorder_step, total_steps = trainEpoch(trainDataLoader, \n",
    "                                                                   train_writer, E, G, opt_E, opt_G, loss,\n",
    "                                                                   rmse, lr_scheduler_E, lr_scheduler_G, \n",
    "                                                                   tensorboard_rate, device,\n",
    "                                                                   tensorboard_recorder_step, total_steps)\n",
    "    \n",
    "    writeMessage(\"trainLoss: {:.4e}\".format(trainLoss),versionName)\n",
    "    E.eval()\n",
    "    G.eval()\n",
    "    valLoss = validEpoch(testDataLoader, test_writer, E, G, p_loss, loss, rmse, device, tensorboard_recorder_step)\n",
    "    \n",
    "    # checkpoint progress\n",
    "    if valLoss < bestLoss:\n",
    "        bestLoss = valLoss\n",
    "        writeMessage(\"Better valLoss: {:.4e}, Saving models...\".format(bestLoss),versionName)\n",
    "        torch.save(E.state_dict(), os.path.join(cps,versionName +'_Encoder'))\n",
    "        torch.save(G.state_dict(), os.path.join(cps,versionName +'_Generator'))\n",
    "\n",
    "writeMessage('---------- Finished Training ----------', versionName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compare: Generated vs. Simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:04:05.808528Z",
     "start_time": "2020-03-17T21:32:23.699Z"
    }
   },
   "outputs": [],
   "source": [
    "E.eval()\n",
    "G.eval()\n",
    "sampleBatch = next(iter(testDataLoader))\n",
    "X,p = sampleBatch\n",
    "X = X.to(device)\n",
    "p = p.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = E(X)\n",
    "    z[:,-p.shape[1]:] = p\n",
    "    X_hat = G(z)\n",
    "    \n",
    "X.shape, p.shape, z.shape, X_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:04:05.810586Z",
     "start_time": "2020-03-17T21:32:23.700Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = 0 # frame in the batch \n",
    "XX = X[idx].detach().cpu().squeeze()\n",
    "XX_hat = X_hat[idx].detach().cpu().squeeze()\n",
    "plotSampleWpredictionByChannel(XX, XX_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:04:05.811810Z",
     "start_time": "2020-03-17T21:32:23.701Z"
    }
   },
   "outputs": [],
   "source": [
    "plotSampleWprediction(XX, XX_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:04:05.812978Z",
     "start_time": "2020-03-17T21:32:23.703Z"
    }
   },
   "outputs": [],
   "source": [
    "plotSample(XX-XX_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize full simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:04:05.814112Z",
     "start_time": "2020-03-17T21:32:23.704Z"
    }
   },
   "outputs": [],
   "source": [
    "simData = getSingleSim(sim=simVizIndex,dataDirec=testData)\n",
    "simDataset = MantaFlowDataset(simData, reverseXY=reverseXY, numToKeep=numSamplesToKeep, AE=False)\n",
    "simDataLoader = DataLoader(simDataset,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-18T04:04:05.815245Z",
     "start_time": "2020-03-17T21:32:23.705Z"
    }
   },
   "outputs": [],
   "source": [
    "E.eval()\n",
    "G.eval()\n",
    "for i, sampleBatch in enumerate(simDataLoader,start=1):\n",
    "    with torch.no_grad():\n",
    "        X,p = sampleBatch\n",
    "        X = X.to(device)\n",
    "        p = p.to(device)\n",
    "        \n",
    "        z = E(X)\n",
    "        z[:,-p.shape[1]:] = p\n",
    "        X_hat = G(z)\n",
    "        \n",
    "        X = X.detach().cpu().squeeze()\n",
    "        X_hat = X_hat.detach().cpu().squeeze()\n",
    "        plotSampleWprediction(X, X_hat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
