{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T00:20:58.169738Z",
     "start_time": "2020-03-06T00:20:58.166986Z"
    }
   },
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:47.666467Z",
     "start_time": "2020-03-28T16:59:47.659260Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from surrogates4sims.utils import printNumModelParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Fluids Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:49.936984Z",
     "start_time": "2020-03-28T16:59:49.891285Z"
    }
   },
   "outputs": [],
   "source": [
    "# EXPORT \n",
    "class convBlock(nn.Module):\n",
    "    def __init__(self,num_conv=4,in_channels=128,filters=128,act=nn.LeakyReLU(),downSample=True):\n",
    "        super(convBlock,self).__init__()\n",
    "        self.num_conv = num_conv\n",
    "        self.in_channels = in_channels\n",
    "        self.act = act\n",
    "        \n",
    "        layers = []\n",
    "        for i in range(num_conv):\n",
    "            if i == 0:\n",
    "                layers.append(nn.Conv2d(in_channels, filters, kernel_size=3, stride=1,padding=1))\n",
    "                layers.append(nn.BatchNorm2d(filters))\n",
    "                layers.append(act)\n",
    "            else:\n",
    "                layers.append(nn.Conv2d(filters, filters, kernel_size=3, stride=1,padding=1))\n",
    "                layers.append(nn.BatchNorm2d(filters))\n",
    "                layers.append(act)\n",
    "        self.convs = nn.Sequential(*layers)\n",
    "        #self.downSampleLayer = nn.Conv2d(in_channels+filters, in_channels+filters,kernel_size=3,stride=2,padding=1)\n",
    "        self.downSampleLayer = nn.Conv2d(filters, filters,kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #print(x.shape)\n",
    "        x0 = x\n",
    "        x = self.convs(x)\n",
    "        #x = torch.cat([x,x0],axis=1)\n",
    "        x = self.downSampleLayer(x)\n",
    "        x = torch.cat([x,F.interpolate(x0,scale_factor=.5)],axis=1)\n",
    "        return x\n",
    "    \n",
    "class convTransBlock(nn.Module):\n",
    "    def __init__(self, num_conv=4, in_channels=128, filters=128, act=nn.LeakyReLU(), skip_connection=False, stack=False):\n",
    "        super(convTransBlock,self).__init__()\n",
    "        self.filters = filters\n",
    "        self.num_conv = num_conv\n",
    "        self.in_channels = in_channels\n",
    "        self.act = act\n",
    "        self.skip_connection = skip_connection\n",
    "        self.stack = stack\n",
    "        self.upsample = torch.nn.modules.Upsample(scale_factor=2)\n",
    "        layers = []\n",
    "        for i in range(num_conv-1):\n",
    "            if i == 0:\n",
    "                layers.append(nn.ConvTranspose2d(in_channels,out_channels=filters, kernel_size=3, stride=1,padding=1))\n",
    "                layers.append(nn.BatchNorm2d(filters))\n",
    "                layers.append(act)\n",
    "            else:\n",
    "                layers.append(nn.ConvTranspose2d(filters,out_channels=filters, kernel_size=3, stride=1,padding=1))\n",
    "                layers.append(nn.BatchNorm2d(filters))\n",
    "                layers.append(act)                \n",
    "        layers.append(nn.ConvTranspose2d(filters, out_channels=filters, kernel_size=3, stride=2,\n",
    "                                         padding=1, output_padding=1))\n",
    "        layers.append(act)\n",
    "        self.seq = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x0 = x\n",
    "        x = self.seq(x)\n",
    "        if self.skip_connection:\n",
    "            x += self.upsample(x0)\n",
    "        if self.stack:\n",
    "            x = torch.cat([x, self.upsample(x0)], axis=1)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,z, filters, output_shape,\n",
    "                 num_conv=4, conv_k=3, last_k=3, repeat=0, \n",
    "                 skip_connection=False, act=nn.LeakyReLU(),stack=False):\n",
    "        super(Generator,self).__init__()\n",
    "        if repeat == 0:\n",
    "            repeat_num = int(np.log2(torch.max(output_shape[1:]))) - 2\n",
    "        else:\n",
    "            repeat_num = repeat\n",
    "        x0_shape = [filters] + [int(i/np.power(2, repeat_num-1)) for i in output_shape[1:]]\n",
    "        self.x0_shape = x0_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.filters = filters\n",
    "        self.num_conv = num_conv\n",
    "        num_output = int(np.prod(x0_shape))\n",
    "        self.num_output = num_output\n",
    "        self.linear = nn.Linear(z.shape[1], num_output)\n",
    "        \n",
    "        convTransBlockLayers = []\n",
    "        ch = filters\n",
    "        for i in range(repeat_num-1):\n",
    "            #print(ch)\n",
    "            convTransBlockLayers.append(convTransBlock(num_conv, ch, filters, act, skip_connection, stack))\n",
    "            if stack:\n",
    "                ch += filters\n",
    "\n",
    "        self.convTransBlockLayers = nn.Sequential(*convTransBlockLayers)\n",
    "        if ch > filters:\n",
    "            n = ch\n",
    "        else:\n",
    "            n = filters\n",
    "        self.lastConv = nn.Conv2d(n,int(output_shape[0]),kernel_size=3, stride=1,padding=1)\n",
    "        self.skip_connection = skip_connection\n",
    "        self.stack = stack\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = x.view(-1,self.x0_shape[0],self.x0_shape[1],self.x0_shape[2])\n",
    "        x = self.convTransBlockLayers(x)\n",
    "        x = self.lastConv(x)\n",
    "        return x\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, x, filters, z_num, num_conv=4, conv_k=3, repeat=0, act=nn.LeakyReLU()):\n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        x_shape = x.shape[1:]\n",
    "        if repeat == 0:\n",
    "            repeat_num = int(np.log2(np.max(x_shape[1:]))) - 2\n",
    "        else:\n",
    "            repeat_num = repeat\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.act = act\n",
    "        self.conv1 = nn.Conv2d(x_shape[0], filters, kernel_size=conv_k, stride=1,padding=1)\n",
    "        \n",
    "        ch = filters\n",
    "        convLayers = []\n",
    "        for idx in range(0,repeat_num):\n",
    "            convLayers.append(convBlock(num_conv, ch, filters, act=nn.LeakyReLU(), downSample=True))\n",
    "            ch += filters\n",
    "            \n",
    "        self.convs = nn.Sequential(*convLayers)\n",
    "        h = [i//2**repeat_num for i in x_shape[1:]]\n",
    "        self.nLinearInput = (ch)*np.prod(h)\n",
    "        self.linear = nn.Linear(self.nLinearInput,z_num)\n",
    "                             \n",
    "    def forward(self,x):\n",
    "        x = self.act(self.conv1(x))\n",
    "        #print(x.shape)\n",
    "        x = self.convs(x)\n",
    "        #print(x.shape)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "class AE_no_P(nn.Module):\n",
    "    def __init__(self, encoder,generator):\n",
    "        super(AE_no_P,self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        #x = torch.cat([x,p],axis=1)\n",
    "        x = self.generator(x)\n",
    "        return x\n",
    "    \n",
    "class AE_xhat_z(nn.Module):\n",
    "    def __init__(self, encoder,generator):\n",
    "        super(AE_xhat_z,self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self,x):\n",
    "        z = self.encoder(x)\n",
    "        x = self.generator(z)\n",
    "        return x, z\n",
    "    \n",
    "class AE_xhat_zV2(nn.Module):\n",
    "    def __init__(self, X, filters=32, latentDim=16, num_conv=2, repeat=0, \n",
    "                 skip_connection=False, stack=False, conv_k=3, last_k=3,\n",
    "                 act=nn.LeakyReLU, return_z=True, stream=True, device='cpu'):\n",
    "        super(AE_xhat_zV2,self).__init__()\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.latentDim = latentDim\n",
    "        self.num_conv = num_conv\n",
    "        self.repeat = repeat\n",
    "        self.skip_connection = skip_connection\n",
    "        self.stack = stack\n",
    "        self.act = act\n",
    "        self.conv_k = 3\n",
    "        self.last_k = 3\n",
    "        self.device = device\n",
    "        self.return_z = return_z\n",
    "        self.stream = stream\n",
    "        \n",
    "        self.encoder = Encoder(X,filters,latentDim,num_conv=num_conv).to(device)\n",
    "        \n",
    "        z = self.encoder(X)\n",
    "        \n",
    "        if stream:\n",
    "            self.output_shape = torch.tensor(X[0][1:].shape)\n",
    "        else:\n",
    "            self.output_shape = torch.tensor(X[0].shape)\n",
    "\n",
    "        self.generator = Generator(z, filters, self.output_shape,\n",
    "                                   num_conv, conv_k, last_k, repeat, \n",
    "                                   skip_connection, act=act, stack=stack).to(device)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        z = self.encoder(x)\n",
    "        x = self.generator(z)\n",
    "        if self.return_z:\n",
    "            return x, z\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T17:05:31.918329Z",
     "start_time": "2020-03-04T17:05:31.915428Z"
    }
   },
   "source": [
    "#### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:50.837316Z",
     "start_time": "2020-03-28T16:59:50.832065Z"
    }
   },
   "outputs": [],
   "source": [
    "bz = 8\n",
    "latentDim = 16\n",
    "filters = 128\n",
    "num_conv = 4\n",
    "num_Gconv= 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:50.999266Z",
     "start_time": "2020-03-28T16:59:50.985622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 128, 96])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn([bz, 2, 128, 96]) #, torch.Size([32, 3]))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:51.662233Z",
     "start_time": "2020-03-28T16:59:51.651807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2, 128,  96])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape = torch.tensor(X[0].shape)\n",
    "output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:52.145706Z",
     "start_time": "2020-03-28T16:59:52.138403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = torch.rand([bz,3])\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:52.324517Z",
     "start_time": "2020-03-28T16:59:52.293708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "convBlock(\n",
       "  (act): LeakyReLU(negative_slope=0.01)\n",
       "  (convs): Sequential(\n",
       "    (0): Conv2d(2, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): LeakyReLU(negative_slope=0.01)\n",
       "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (downSampleLayer): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = convBlock(num_conv=num_conv,in_channels=X.shape[1],filters=filters)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:53.540243Z",
     "start_time": "2020-03-28T16:59:52.875121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 130, 64, 48])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = C(X)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:53.551411Z",
     "start_time": "2020-03-28T16:59:53.541694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 128, 8, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTB = convTransBlock(num_conv=num_conv, filters=128, act=nn.LeakyReLU(), skip_connection=False, stack=True)\n",
    "XX = torch.randn([bz, 128,8,6]) #, torch.Size([32, 3]))\n",
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:53.645979Z",
     "start_time": "2020-03-28T16:59:53.552748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256, 16, 12])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = CTB(XX)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:53.805896Z",
     "start_time": "2020-03-28T16:59:53.756241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (act): LeakyReLU(negative_slope=0.01)\n",
       "  (conv1): Conv2d(2, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (convs): Sequential(\n",
       "    (0): convBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): LeakyReLU(negative_slope=0.01)\n",
       "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (11): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (downSampleLayer): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): convBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): LeakyReLU(negative_slope=0.01)\n",
       "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (11): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (downSampleLayer): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (2): convBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): LeakyReLU(negative_slope=0.01)\n",
       "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (11): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (downSampleLayer): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (3): convBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): LeakyReLU(negative_slope=0.01)\n",
       "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (11): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (downSampleLayer): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (4): convBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (convs): Sequential(\n",
       "        (0): Conv2d(640, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): LeakyReLU(negative_slope=0.01)\n",
       "        (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): LeakyReLU(negative_slope=0.01)\n",
       "        (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (11): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "      (downSampleLayer): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=9216, out_features=16, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = Encoder(X,filters,latentDim,num_conv=num_conv)\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:54.578603Z",
     "start_time": "2020-03-28T16:59:54.571260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 layers require gradients (unfrozen) out of 94 layers\n",
      "5,319,184 parameters require gradients (unfrozen) out of 5,319,184 parameters\n"
     ]
    }
   ],
   "source": [
    "printNumModelParams(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:55.588310Z",
     "start_time": "2020-03-28T16:59:54.729458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = E(X)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:55.593257Z",
     "start_time": "2020-03-28T16:59:55.589866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2, 128,  96])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_shape = torch.tensor(X.shape[1:])\n",
    "output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-04T17:16:02.189739Z",
     "start_time": "2020-03-04T17:16:02.186886Z"
    }
   },
   "source": [
    "##### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:55.822196Z",
     "start_time": "2020-03-28T16:59:55.816288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 19])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.randn(bz, latentDim + p.shape[1])\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:56.011580Z",
     "start_time": "2020-03-28T16:59:55.983484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (linear): Linear(in_features=19, out_features=6144, bias=True)\n",
       "  (convTransBlockLayers): Sequential(\n",
       "    (0): convTransBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (4): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (1): convTransBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (4): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (2): convTransBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (4): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (3): convTransBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (4): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lastConv): Conv2d(640, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = Generator(z, 128, output_shape,\n",
    "                 num_conv=2, conv_k=3, last_k=3, repeat=0, \n",
    "                 skip_connection=False, act=nn.LeakyReLU(),stack=True)\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:56.399918Z",
     "start_time": "2020-03-28T16:59:56.393607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 layers require gradients (unfrozen) out of 28 layers\n",
      "2,200,834 parameters require gradients (unfrozen) out of 2,200,834 parameters\n"
     ]
    }
   ],
   "source": [
    "printNumModelParams(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:58.098521Z",
     "start_time": "2020-03-28T16:59:56.560274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 128, 96])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = G(z)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:58.108045Z",
     "start_time": "2020-03-28T16:59:58.100037Z"
    }
   },
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "class GeneratorOld(nn.Module):\n",
    "    def __init__(self,z, filters, output_shape,\n",
    "                 num_conv=4, conv_k=3, last_k=3, repeat=0, \n",
    "                 skip_connection=False, act=nn.LeakyReLU()):\n",
    "        super(GeneratorOld,self).__init__()\n",
    "        if repeat == 0:\n",
    "            repeat_num = int(np.log2(torch.max(output_shape[1:]))) - 2\n",
    "        else:\n",
    "            repeat_num = repeat\n",
    "        x0_shape = [filters] + [int(i/np.power(2, repeat_num-1)) for i in output_shape[1:]]\n",
    "        self.x0_shape = x0_shape\n",
    "        num_output = int(np.prod(x0_shape))\n",
    "        self.linear = nn.Linear(z.shape[1], num_output)\n",
    "        convTransBlockLayers = []\n",
    "        for i in range(repeat_num-1):\n",
    "            convTransBlockLayers.append(convTransBlock(num_conv,filters,act,skip_connection))\n",
    "        self.convTransBlockLayers = nn.Sequential(*convTransBlockLayers)\n",
    "        self.lastConv = nn.Conv2d(filters,int(output_shape[0]),kernel_size=3, stride=1,padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = x.view(-1,self.x0_shape[0],self.x0_shape[1],self.x0_shape[2])\n",
    "        x = self.convTransBlockLayers(x)\n",
    "        #x = self.lastConv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:58.344907Z",
     "start_time": "2020-03-28T16:59:58.109581Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5f8f5c9fd269>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  skip_connection=False, act=nn.LeakyReLU())\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'AE' is not defined"
     ]
    }
   ],
   "source": [
    "E = Encoder(X,filters,latentDim,num_conv=num_conv)\n",
    "G = Generator(z, num_Gconv, output_shape,\n",
    "                 num_conv=num_conv, conv_k=3, last_k=3, repeat=0, \n",
    "                 skip_connection=False, act=nn.LeakyReLU())\n",
    "\n",
    "model = AE(E,G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:58.346224Z",
     "start_time": "2020-03-28T16:59:57.000Z"
    }
   },
   "outputs": [],
   "source": [
    "Xhat = model(X,p)\n",
    "Xhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:58.346949Z",
     "start_time": "2020-03-28T16:59:57.152Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "loss_func = torch.nn.MSELoss()\n",
    "loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:58.347714Z",
     "start_time": "2020-03-28T16:59:57.319Z"
    }
   },
   "outputs": [],
   "source": [
    "mseVal = loss_func(X,model(X,p))\n",
    "mseVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build AE_no_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:59.741649Z",
     "start_time": "2020-03-28T16:59:58.889506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = E(X)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:59.761853Z",
     "start_time": "2020-03-28T16:59:59.743055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (linear): Linear(in_features=16, out_features=6144, bias=True)\n",
       "  (convTransBlockLayers): Sequential(\n",
       "    (0): convTransBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (4): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (1): convTransBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (4): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (2): convTransBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (4): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (3): convTransBlock(\n",
       "      (act): LeakyReLU(negative_slope=0.01)\n",
       "      (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "      (seq): Sequential(\n",
       "        (0): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): LeakyReLU(negative_slope=0.01)\n",
       "        (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "        (4): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lastConv): Conv2d(640, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = Generator(z, 128, output_shape,\n",
    "                 num_conv=2, conv_k=3, last_k=3, repeat=0, \n",
    "                 skip_connection=False, act=nn.LeakyReLU(),stack=True)\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T16:59:59.765357Z",
     "start_time": "2020-03-28T16:59:59.763295Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AE_no_P(E,G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T17:00:02.105509Z",
     "start_time": "2020-03-28T16:59:59.766608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 128, 96])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(X)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build AE_xhat_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T17:00:02.110910Z",
     "start_time": "2020-03-28T17:00:02.106973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AE_xhat_z(\n",
       "  (encoder): Encoder(\n",
       "    (act): LeakyReLU(negative_slope=0.01)\n",
       "    (conv1): Conv2d(2, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (convs): Sequential(\n",
       "      (0): convBlock(\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01)\n",
       "          (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (8): LeakyReLU(negative_slope=0.01)\n",
       "          (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (11): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (downSampleLayer): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (1): convBlock(\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01)\n",
       "          (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (8): LeakyReLU(negative_slope=0.01)\n",
       "          (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (11): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (downSampleLayer): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (2): convBlock(\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01)\n",
       "          (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (8): LeakyReLU(negative_slope=0.01)\n",
       "          (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (11): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (downSampleLayer): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (3): convBlock(\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01)\n",
       "          (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (8): LeakyReLU(negative_slope=0.01)\n",
       "          (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (11): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (downSampleLayer): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "      (4): convBlock(\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "        (convs): Sequential(\n",
       "          (0): Conv2d(640, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): LeakyReLU(negative_slope=0.01)\n",
       "          (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (8): LeakyReLU(negative_slope=0.01)\n",
       "          (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (11): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (downSampleLayer): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (linear): Linear(in_features=9216, out_features=16, bias=True)\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (linear): Linear(in_features=16, out_features=6144, bias=True)\n",
       "    (convTransBlockLayers): Sequential(\n",
       "      (0): convTransBlock(\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "        (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (seq): Sequential(\n",
       "          (0): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (4): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): convTransBlock(\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "        (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (seq): Sequential(\n",
       "          (0): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (4): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (2): convTransBlock(\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "        (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (seq): Sequential(\n",
       "          (0): ConvTranspose2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (4): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (3): convTransBlock(\n",
       "        (act): LeakyReLU(negative_slope=0.01)\n",
       "        (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (seq): Sequential(\n",
       "          (0): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "          (3): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
       "          (4): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lastConv): Conv2d(640, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = AE_xhat_z(E,G)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T17:00:04.470807Z",
     "start_time": "2020-03-28T17:00:02.112272Z"
    }
   },
   "outputs": [],
   "source": [
    "xhat, z = m(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T17:00:04.475252Z",
     "start_time": "2020-03-28T17:00:04.472328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 2, 128, 96]), torch.Size([8, 16]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xhat.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
